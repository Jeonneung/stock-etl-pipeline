{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f4fe19",
   "metadata": {},
   "source": [
    "# 과거 미국 주식 랠리 분석 — 다음 랠리의 승자는 누구인가?\n",
    "\n",
    "**분석 기간: 2026.02.02 ~**\n",
    "\n",
    "> **Executive Summary**\n",
    "> \n",
    "> 1988~2000년 닷컴 버블을 **12년 전체(그룹 1)**와 **버블 말기 1년(그룹 2)**으로 나눠 분석한 결과:\n",
    "> \n",
    "> **그룹 1 (162개 종목, 12년)**: 중앙값 3.88배 수익, 손실 비율 2%. 슈퍼 성장 클러스터(7.4배)에서 Financial Services(14개)가 Technology(7개)보다 많았다. 12년간 일관되게 나스닥을 이긴 종목은 단 3개(AB, AEG, LEG).\n",
    "> \n",
    "> **그룹 2 (339개 종목, 1년)**: 중앙값 1.08배, 손실 비율 37%. Technology가 폭등 클러스터에 집중되었으나 양극화 극심.\n",
    "> \n",
    "> **주요 한계**: 현재 상장 종목 기준으로 수집하여 **Survivorship Bias 존재**. 상장폐지된 닷컴 버블 핵심 종목(YHOO, SUNW 등)이 누락되어 손실 비율이 과소추정되었을 가능성이 높다.\n",
    "\n",
    "---\n",
    "\n",
    "## 배경\n",
    "\n",
    "2026년 하반기, 중간선거를 앞두고 미국 주식시장의 랠리가 예상된다. 이후 AI 버블이 본격화될 가능성까지 고려하면, 지금 시점에서 **\"랠리 때 어떤 종목이 주로 상승하는가\"** 를 과거 데이터로 검증해볼 필요가 있다.\n",
    "\n",
    "분석 대상으로 **1988~2000년 닷컴 버블 랠리**를 선택했다. 기술 혁신이 주도한 장기 상승장이라는 점에서 현재 AI 랠리와 구조적 유사성이 있기 때문이다.\n",
    "\n",
    "## 질문 설정\n",
    "\n",
    "1. 12년간의 랠리에서 실제로 큰 수익을 낸 종목은 어떤 특징을 갖고 있는가?\n",
    "2. 테크 섹터만 올랐는가, 아니면 다른 섹터에서도 승자가 나왔는가?\n",
    "3. 버블 말기(1년)와 전체 랠리(12년)의 패턴은 어떻게 다른가?\n",
    "4. 이 패턴이 현재 AI 랠리에 시사하는 점은?\n",
    "\n",
    "## 분석 대상\n",
    "\n",
    "| 구분 | 기간 | 설명 |\n",
    "|------|------|------|\n",
    "| 그룹 1 (Full Coverage) | 1988.10 ~ 2000.03 | 12년 전체 랠리를 경험한 장기 생존 종목 162개 |\n",
    "| 그룹 2 (Bubble End) | 1999.03 ~ 2000.03 | 버블 말기 1년 동안 존재한 전체 종목 339개 |\n",
    "\n",
    "## 한계\n",
    "\n",
    "- **Survivorship Bias**: 현재 상장 종목 기준으로 수집. 상장폐지 종목(YHOO, SUNW, CMGI 등)이 누락되어 손실 비율과 하락 클러스터가 과소추정됨\n",
    "- 이로 인해 \"12년 보유 시 손실 2%\"라는 결과는 실제보다 낙관적일 가능성 높음\n",
    "- 추후 FMP API로 상장폐지 종목까지 포함하여 재분석 예정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e93224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 분석 기간 설정\n",
    "START_DATE = \"1988-10-01\"\n",
    "END_DATE = \"2000-03-31\"\n",
    "\n",
    "print(f\"분석 기간: {START_DATE} ~ {END_DATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ufokmaf2scq",
   "metadata": {},
   "source": [
    "## 1. 데이터 수집\n",
    "\n",
    "NASDAQ Trader에서 현재 상장된 전체 종목(NASDAQ + NYSE 등) 티커를 수집하고, 주요 지수 심볼을 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z1gy4rdxs5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tickers = set()\n",
    "\n",
    "# --- NASDAQ Trader FTP - 전체 상장 종목 ---\n",
    "try:\n",
    "    # NASDAQ 거래소 상장 종목\n",
    "    nasdaq_listed = pd.read_csv(\n",
    "        \"https://www.nasdaqtrader.com/dynamic/SymDir/nasdaqlisted.txt\",\n",
    "        sep=\"|\"\n",
    "    )\n",
    "    nasdaq_listed = nasdaq_listed[nasdaq_listed[\"Test Issue\"] == \"N\"]\n",
    "    nasdaq_syms = set(nasdaq_listed[\"Symbol\"].dropna().tolist())\n",
    "    # 기타 거래소 (NYSE 등)\n",
    "    other_listed = pd.read_csv(\n",
    "        \"https://www.nasdaqtrader.com/dynamic/SymDir/otherlisted.txt\",\n",
    "        sep=\"|\"\n",
    "    )\n",
    "    if \"Test Issue\" in other_listed.columns:\n",
    "        other_listed = other_listed[other_listed[\"Test Issue\"] == \"N\"]\n",
    "    if \"ACT Symbol\" in other_listed.columns:\n",
    "        other_syms = set(other_listed[\"ACT Symbol\"].dropna().tolist())\n",
    "    elif \"Symbol\" in other_listed.columns:\n",
    "        other_syms = set(other_listed[\"Symbol\"].dropna().tolist())\n",
    "    else:\n",
    "        other_syms = set()\n",
    "    \n",
    "    exchange_tickers = nasdaq_syms | other_syms\n",
    "    # 일반 주식만 필터링 (ETF, 워런트 등 제외를 위해 특수문자 포함 티커 제거)\n",
    "    exchange_tickers = {t for t in exchange_tickers if isinstance(t, str) and t.isalpha() and len(t) <= 5}\n",
    "    all_tickers.update(exchange_tickers)\n",
    "    print(f\"NASDAQ Trader (NASDAQ + 기타 거래소): {len(exchange_tickers)}개\")\n",
    "except Exception as e:\n",
    "    print(f\"NASDAQ Trader 수집 실패: {e}\")\n",
    "\n",
    "# --- 주요 지수 심볼 추가 ---\n",
    "index_tickers = {\"^GSPC\", \"^DJI\", \"^IXIC\", \"^RUT\", \"^NYA\"}\n",
    "all_tickers.update(index_tickers)\n",
    "\n",
    "print(f\"\\n총 고유 티커 수: {len(all_tickers)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanv24nzrcg",
   "metadata": {},
   "source": [
    "## 2. yfinance 배치 다운로드\n",
    "\n",
    "11,724개 티커를 100개씩 배치로 나눠 1988.10~2000.03 기간의 종가 데이터를 다운로드한다. 현재 상장 종목 기준이므로 해당 기간에 존재하지 않았던 종목은 데이터가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2zbs0z6v4ds",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_batch(tickers, start, end, batch_size=100):\n",
    "    \"\"\"티커를 배치로 나눠서 yfinance에서 다운로드\"\"\"\n",
    "    ticker_list = sorted(list(tickers))\n",
    "    all_data = {}\n",
    "    failed = []\n",
    "    \n",
    "    total_batches = (len(ticker_list) + batch_size - 1) // batch_size\n",
    "    \n",
    "    for i in range(0, len(ticker_list), batch_size):\n",
    "        batch = ticker_list[i:i+batch_size]\n",
    "        batch_num = i // batch_size + 1\n",
    "        print(f\"배치 {batch_num}/{total_batches} 다운로드 중... ({len(batch)}개 티커)\")\n",
    "        \n",
    "        try:\n",
    "            data = yf.download(\n",
    "                tickers=batch,\n",
    "                start=start,\n",
    "                end=end,\n",
    "                auto_adjust=True,\n",
    "                progress=False,\n",
    "                threads=True\n",
    "            )\n",
    "            \n",
    "            if data.empty:\n",
    "                continue\n",
    "            \n",
    "            # 단일 티커인 경우 MultiIndex가 아님\n",
    "            if len(batch) == 1:\n",
    "                ticker = batch[0]\n",
    "                if not data.empty:\n",
    "                    all_data[ticker] = data[\"Close\"]\n",
    "            else:\n",
    "                # MultiIndex columns: (Price, Ticker)\n",
    "                if isinstance(data.columns, pd.MultiIndex):\n",
    "                    close_data = data[\"Close\"]\n",
    "                else:\n",
    "                    close_data = data\n",
    "                \n",
    "                for ticker in close_data.columns:\n",
    "                    col = close_data[ticker].dropna()\n",
    "                    if len(col) > 0:\n",
    "                        all_data[ticker] = col\n",
    "                        \n",
    "        except Exception as e:\n",
    "            failed.extend(batch)\n",
    "            print(f\"  배치 {batch_num} 실패: {e}\")\n",
    "        \n",
    "        # API rate limit 방지\n",
    "        if batch_num % 5 == 0:\n",
    "            time.sleep(1)\n",
    "    \n",
    "    print(f\"\\n다운로드 완료: {len(all_data)}개 종목 데이터 확보\")\n",
    "    if failed:\n",
    "        print(f\"실패한 티커: {len(failed)}개\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "# 다운로드 실행\n",
    "stock_data = download_batch(all_tickers, START_DATE, END_DATE, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "w0oq5u59mvp",
   "metadata": {},
   "source": [
    "## 3. 데이터 필터링\n",
    "\n",
    "11,724개 중 360개만 해당 기간 데이터가 존재했다. 대부분의 현재 상장 종목은 2000년 이후 IPO이므로 정상적인 결과다. 최소 250거래일(약 1년) 이상 데이터를 보유한 339개 종목을 분석 대상으로 선정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u2i3ki2l9pn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최소 거래일 수 기준으로 필터링 (최소 250일 = 약 1년)\n",
    "MIN_TRADING_DAYS = 250\n",
    "\n",
    "valid_tickers = {k: v for k, v in stock_data.items() if len(v) >= MIN_TRADING_DAYS}\n",
    "\n",
    "print(f\"전체 다운로드 종목: {len(stock_data)}개\")\n",
    "print(f\"최소 {MIN_TRADING_DAYS}거래일 이상 데이터 보유: {len(valid_tickers)}개\")\n",
    "\n",
    "# 종합 DataFrame 생성\n",
    "close_df = pd.DataFrame(valid_tickers)\n",
    "close_df.index = pd.to_datetime(close_df.index)\n",
    "close_df = close_df.sort_index()\n",
    "\n",
    "print(f\"\\n데이터 기간: {close_df.index[0].date()} ~ {close_df.index[-1].date()}\")\n",
    "print(f\"총 거래일: {len(close_df)}\")\n",
    "print(f\"종목 수: {close_df.shape[1]}\")\n",
    "\n",
    "# 기간별 커버리지 확인\n",
    "coverage = close_df.notna().sum(axis=1)\n",
    "print(f\"\\n일자별 평균 종목 수: {coverage.mean():.0f}\")\n",
    "print(f\"일자별 최소 종목 수: {coverage.min()} ({coverage.idxmin().date()})\")\n",
    "print(f\"일자별 최대 종목 수: {coverage.max()} ({coverage.idxmax().date()})\")\n",
    "\n",
    "# 수익률 계산\n",
    "returns_df = close_df.pct_change()\n",
    "\n",
    "# 기간 전체 수익률 (처음~끝)\n",
    "total_returns = {}\n",
    "for col in close_df.columns:\n",
    "    series = close_df[col].dropna()\n",
    "    if len(series) >= 2:\n",
    "        total_returns[col] = (series.iloc[-1] / series.iloc[0] - 1) * 100\n",
    "\n",
    "total_returns_series = pd.Series(total_returns).sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\n=== 기간 전체 수익률 상위 20 ===\")\n",
    "print(total_returns_series.head(20).to_string(float_format=\"{:.1f}%\".format))\n",
    "print(f\"\\n=== 기간 전체 수익률 하위 10 ===\")\n",
    "print(total_returns_series.tail(10).to_string(float_format=\"{:.1f}%\".format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0fc008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 처리: 기간별 분리\n",
    "# 첫 번째 분석 대상: 1988-10-01 ~ 2000-03-31 기간에 결측치가 없는 데이터: 162개 종목\n",
    "close_df_1 = close_df.loc[\"1988-10-01\":\"2000-03-31\"]\n",
    "close_df_1 = close_df_1.dropna(axis=1)\n",
    "print(f\"첫 번째 분석 대상 종목 수: {close_df_1.shape[1]}개\")\n",
    "\n",
    "# 두 번째 분석 대상: 1999-03-31 ~ 2000-12-31 기간에 결측치가 없는 데이터: 339개 종목\n",
    "close_df_2 = close_df.loc[\"1999-03-31\":\"2000-12-31\"]\n",
    "close_df_2 = close_df_2.dropna(axis=1) # 만약을 대비\n",
    "print(f\"두 번째 분석 대상 종목 수: {close_df_2.shape[1]}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vpecqy0epg",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화 (시작점 = 100)\n",
    "normalized_1 = close_df_1.apply(lambda x: x / x.iloc[0] * 100)\n",
    "print(f\"그룹 1 정규화 완료: {normalized_1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ac945",
   "metadata": {},
   "source": [
    "## 4. 시각화 — 162개 풀 커버리지 종목의 랠리 흐름\n",
    "\n",
    "339개 종목 중 12년 전체 기간에 결측치가 없는 162개 종목(그룹 1)을 시작가=100으로 정규화하여 시각화한다. 개별 종목은 배경으로, 전체 중앙값을 기준선으로 표시한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05fe85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# ==================== 공통 함수 정의 ====================\n",
    "\n",
    "def collect_sectors(tickers):\n",
    "    \"\"\"yfinance에서 섹터 정보 수집\"\"\"\n",
    "    sectors = {}\n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            info = yf.Ticker(ticker).info\n",
    "            sectors[ticker] = info.get('sector', 'Unknown')\n",
    "        except:\n",
    "            sectors[ticker] = 'Unknown'\n",
    "    return pd.Series(sectors)\n",
    "\n",
    "def create_sector_colors(sector_series):\n",
    "    \"\"\"섹터별 색상 매핑 생성\"\"\"\n",
    "    unique_sectors = sector_series.unique()\n",
    "    cmap = plt.cm.get_cmap('tab10', len(unique_sectors))\n",
    "    return {sector: cmap(i) for i, sector in enumerate(sorted(unique_sectors))}\n",
    "\n",
    "def plot_sector_chart(normalized_df, sector_series, sector_colors, title):\n",
    "    \"\"\"섹터별 색상으로 로그 스케일 차트 그리기\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(14, 7))\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    for sector, tickers in sector_series.groupby(sector_series):\n",
    "        color = sector_colors.get(sector, 'grey')\n",
    "        for ticker in tickers.index:\n",
    "            if ticker in normalized_df.columns:\n",
    "                ax.plot(normalized_df[ticker], color=color, alpha=0.3, linewidth=0.7)\n",
    "        ax.plot([], [], color=color, linewidth=2, label=f'{sector} ({len(tickers)})')\n",
    "    \n",
    "    ax.plot(normalized_df.median(axis=1), color='black', linewidth=2.5, linestyle='--', label='Median')\n",
    "    ax.legend(fontsize=8, loc='upper left', ncol=2)\n",
    "    ax.set_ylabel('Normalized Price (Start=100, Log Scale)')\n",
    "    ax.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def find_optimal_clusters(X, k_range=range(2, 11)):\n",
    "    \"\"\"Elbow Method와 Silhouette Score로 최적 클러스터 수 탐색\"\"\"\n",
    "    inertias, sil_scores = [], []\n",
    "    for k in k_range:\n",
    "        km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        labels = km.fit_predict(X)\n",
    "        inertias.append(km.inertia_)\n",
    "        sil_scores.append(silhouette_score(X, labels))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    axes[0].plot(k_range, inertias, marker='o')\n",
    "    axes[0].set_title('Elbow Method')\n",
    "    axes[0].set_xlabel('k')\n",
    "    axes[0].set_ylabel('Inertia')\n",
    "    axes[1].plot(k_range, sil_scores, marker='o', color='orange')\n",
    "    axes[1].set_title('Silhouette Score')\n",
    "    axes[1].set_xlabel('k')\n",
    "    axes[1].set_ylabel('Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return inertias, sil_scores\n",
    "\n",
    "def run_clustering(normalized_df, n_clusters):\n",
    "    \"\"\"K-Means 클러스터링 실행\"\"\"\n",
    "    log_norm = np.log(normalized_df)\n",
    "    X = StandardScaler().fit_transform(log_norm.T)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    cluster_df = pd.DataFrame({'Ticker': normalized_df.columns, 'Cluster': clusters})\n",
    "    return kmeans, cluster_df, X\n",
    "\n",
    "def plot_cluster_chart(normalized_df, cluster_df, sector_series, sector_colors, n_clusters):\n",
    "    \"\"\"클러스터별 섹터 색상 차트 그리기\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for c in range(n_clusters):\n",
    "        ax = axes[c]\n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "        cluster_tickers = cluster_df[cluster_df['Cluster'] == c]['Ticker']\n",
    "        cluster_data = normalized_df[cluster_tickers]\n",
    "        \n",
    "        for ticker in cluster_tickers:\n",
    "            sector = sector_series.get(ticker, 'Unknown')\n",
    "            color = sector_colors.get(sector, 'grey')\n",
    "            ax.plot(cluster_data[ticker], color=color, alpha=0.3, linewidth=0.7)\n",
    "        \n",
    "        cluster_median = cluster_data.median(axis=1)\n",
    "        ax.plot(cluster_median, color='black', linewidth=2.5, linestyle='--', label=f'Cluster {c} Median')\n",
    "        \n",
    "        cluster_sectors = sector_series[cluster_tickers].value_counts()\n",
    "        for sector, count in cluster_sectors.items():\n",
    "            ax.plot([], [], color=sector_colors.get(sector, 'grey'), linewidth=2, label=f'{sector} ({count})')\n",
    "        \n",
    "        ax.legend(fontsize=7, loc='upper left', ncol=2)\n",
    "        ax.set_title(f'Cluster {c} ({len(cluster_tickers)} stocks)')\n",
    "        ax.set_ylabel('Normalized Price (Log)')\n",
    "    \n",
    "    # 남는 subplot 숨기기\n",
    "    for i in range(n_clusters, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def summarize_clusters(normalized_df, cluster_df, sector_series, n_clusters):\n",
    "    \"\"\"클러스터별 통계 요약 출력\"\"\"\n",
    "    for c in range(n_clusters):\n",
    "        cluster_tickers = cluster_df[cluster_df['Cluster'] == c]['Ticker']\n",
    "        cluster_data = normalized_df[cluster_tickers]\n",
    "        final_vals = cluster_data.iloc[-1]\n",
    "        \n",
    "        print(f\"=== Cluster {c} ({len(cluster_tickers)} stocks) ===\")\n",
    "        print(f\"  중앙값 최종: {cluster_data.median(axis=1).iloc[-1]:.1f} (={cluster_data.median(axis=1).iloc[-1]/100:.1f}x)\")\n",
    "        print(f\"  평균 최종:   {final_vals.mean():.1f} (={final_vals.mean()/100:.1f}x)\")\n",
    "        print(f\"  범위:        {final_vals.min():.1f} ~ {final_vals.max():.1f}\")\n",
    "        \n",
    "        cluster_sectors = sector_series[cluster_tickers].value_counts()\n",
    "        print(f\"  섹터 구성:\")\n",
    "        for sector, count in cluster_sectors.items():\n",
    "            print(f\"    {sector}: {count}개\")\n",
    "        \n",
    "        top3 = final_vals.nlargest(3)\n",
    "        print(f\"  상위 3종목: {', '.join([f'{t}({v:.0f})' for t, v in top3.items()])}\")\n",
    "        print()\n",
    "\n",
    "def calculate_rs(normalized_df, index_ticker='^IXIC'):\n",
    "    \"\"\"상대강도(RS) 계산\"\"\"\n",
    "    if index_ticker not in normalized_df.columns:\n",
    "        print(f\"{index_ticker} 데이터가 없습니다\")\n",
    "        return None\n",
    "    index_norm = normalized_df[index_ticker] / normalized_df[index_ticker].iloc[0]\n",
    "    rs_df = normalized_df.div(index_norm * 100, axis=0)\n",
    "    return rs_df\n",
    "\n",
    "def classify_rs_pattern(rs_series, median_series):\n",
    "    \"\"\"RS 패턴을 4가지로 분류\"\"\"\n",
    "    rs = rs_series.dropna()\n",
    "    med = median_series.loc[rs.index]\n",
    "    \n",
    "    if len(rs) < 10:\n",
    "        return None\n",
    "    \n",
    "    mid = len(rs) // 2\n",
    "    first_half, second_half = rs.iloc[:mid], rs.iloc[mid:]\n",
    "    med_first, med_second = med.iloc[:mid], med.iloc[mid:]\n",
    "    \n",
    "    first_above = (first_half > med_first).mean() > 0.6\n",
    "    first_below = (first_half < med_first).mean() > 0.6\n",
    "    second_above = (second_half > med_second).mean() > 0.6\n",
    "    second_below = (second_half < med_second).mean() > 0.6\n",
    "    \n",
    "    if first_above and second_above: return 1  # 항상 위\n",
    "    elif first_below and second_above: return 2  # 골든크로스\n",
    "    elif first_above and second_below: return 3  # 데드크로스\n",
    "    elif first_below and second_below: return 4  # 항상 아래\n",
    "    else: return 0  # 분류 불가\n",
    "\n",
    "def analyze_rs_patterns(rs_df, periods, sector_series, index_ticker='^IXIC'):\n",
    "    \"\"\"기간별 RS 패턴 분석\"\"\"\n",
    "    pattern_results = {}\n",
    "    \n",
    "    for period_name, start, end in periods:\n",
    "        rs_period = rs_df.loc[start:end]\n",
    "        rs_period_norm = rs_period / rs_period.iloc[0]\n",
    "        rs_median = rs_period_norm.drop(columns=[index_ticker], errors='ignore').median(axis=1)\n",
    "        \n",
    "        period_patterns = {}\n",
    "        for ticker in rs_period_norm.columns:\n",
    "            if ticker == index_ticker:\n",
    "                continue\n",
    "            pattern = classify_rs_pattern(rs_period_norm[ticker], rs_median)\n",
    "            if pattern is not None:\n",
    "                period_patterns[ticker] = pattern\n",
    "        \n",
    "        pattern_results[period_name] = period_patterns\n",
    "        \n",
    "        counts = Counter(period_patterns.values())\n",
    "        print(f\"\\n=== {period_name} ===\")\n",
    "        print(f\"1. 항상 위: {counts.get(1, 0)}개\")\n",
    "        print(f\"2. 골든크로스: {counts.get(2, 0)}개\")\n",
    "        print(f\"3. 데드크로스: {counts.get(3, 0)}개\")\n",
    "        print(f\"4. 항상 아래: {counts.get(4, 0)}개\")\n",
    "        print(f\"0. 분류불가: {counts.get(0, 0)}개\")\n",
    "    \n",
    "    return pattern_results\n",
    "\n",
    "def find_consistent_patterns(pattern_results, sector_series):\n",
    "    \"\"\"전 기간 일관된 패턴 종목 찾기\"\"\"\n",
    "    ticker_patterns = defaultdict(list)\n",
    "    for period_name, patterns in pattern_results.items():\n",
    "        for ticker, pattern in patterns.items():\n",
    "            ticker_patterns[ticker].append((period_name, pattern))\n",
    "    \n",
    "    n_periods = len(pattern_results)\n",
    "    always_above = [t for t, p in ticker_patterns.items() if len(p) == n_periods and all(x[1] == 1 for x in p)]\n",
    "    always_below = [t for t, p in ticker_patterns.items() if len(p) == n_periods and all(x[1] == 4 for x in p)]\n",
    "    rising = [t for t, p in ticker_patterns.items() if len(p) == n_periods and p[0][1] in [4, 0] and p[-1][1] == 1]\n",
    "    falling = [t for t, p in ticker_patterns.items() if len(p) == n_periods and p[0][1] == 1 and p[-1][1] in [4, 0]]\n",
    "    \n",
    "    print(\"=== 전 기간 일관된 패턴 ===\\n\")\n",
    "    print(f\"1. 항상 나스닥을 이긴 종목 ({len(always_above)}개):\")\n",
    "    for t in always_above:\n",
    "        print(f\"  {t} ({sector_series.get(t, 'Unknown')})\")\n",
    "    print(f\"\\n2. 항상 나스닥에 진 종목 ({len(always_below)}개):\")\n",
    "    for t in always_below:\n",
    "        print(f\"  {t} ({sector_series.get(t, 'Unknown')})\")\n",
    "    print(f\"\\n3. 초기 약세 → 후기 강세 ({len(rising)}개):\")\n",
    "    for t in rising:\n",
    "        print(f\"  {t} ({sector_series.get(t, 'Unknown')})\")\n",
    "    print(f\"\\n4. 초기 강세 → 후기 약세 ({len(falling)}개):\")\n",
    "    for t in falling:\n",
    "        print(f\"  {t} ({sector_series.get(t, 'Unknown')})\")\n",
    "    \n",
    "    return always_above, always_below, rising, falling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c054210",
   "metadata": {},
   "source": [
    "### 로그 스케일 + 섹터별 색상\n",
    "\n",
    "가격 편차가 100배 이상이므로 로그 스케일을 적용해야 수익률 흐름이 정확히 보인다. 개별 종목에 섹터별 색상을 입혀 **질문 2: \"테크 섹터만 올랐는가?\"** 를 시각적으로 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76049be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 섹터 정보 수집\n",
    "sectors = {}\n",
    "for ticker in close_df_1.columns:\n",
    "    try:\n",
    "        info = yf.Ticker(ticker).info\n",
    "        sectors[ticker] = info.get('sector', 'Unknown')\n",
    "    except Exception as e:\n",
    "        sectors[ticker] = 'Unknown'\n",
    "sector_df = pd.Series(sectors)\n",
    "sector_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ccd924",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# 섹터별 색상 매핑\n",
    "unique_sectors = sector_df.unique()\n",
    "cmap = plt.cm.get_cmap('tab10', len(unique_sectors))\n",
    "sector_colors = {sector: cmap(i) for i, sector in enumerate(sorted(unique_sectors))}\n",
    "\n",
    "# 섹터별로 개별 종목 그리기\n",
    "for sector, tickers in sector_df.groupby(sector_df):\n",
    "    color = sector_colors[sector]\n",
    "    for ticker in tickers.index:\n",
    "        if ticker in normalized_1.columns:\n",
    "            ax.plot(normalized_1[ticker], color=color, alpha=0.3, linewidth=0.7)\n",
    "    # 범례용 더미 라인 (섹터당 1개)\n",
    "    ax.plot([], [], color=color, linewidth=2, label=f'{sector} ({len(tickers)})')\n",
    "\n",
    "# 중앙값 선\n",
    "ax.plot(normalized_1.median(axis=1), color='black', linewidth=2.5, linestyle='--', label='Median')\n",
    "\n",
    "ax.legend(fontsize=8, loc='upper left', ncol=2)\n",
    "ax.set_ylabel('Normalized Price (Start=100, Log Scale)')\n",
    "ax.set_title('1988.10 ~ 2000.03 Rally by Sector (162 stocks)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34617dc4",
   "metadata": {},
   "source": [
    "## 5. 클러스터링 — 질문 1: \"큰 수익을 낸 종목의 특징은?\"\n",
    "\n",
    "로그 정규화된 가격 시계열을 K-Means로 클러스터링하여, 비슷한 시기에 비슷한 주가 흐름을 보인 종목들을 그룹화한다. 각 클러스터의 섹터 구성과 수익률 분포를 비교하여 **슈퍼 성장주의 공통점**을 찾는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479f7987",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n",
    "\n",
    "Elbow Method와 Silhouette Score로 최적 클러스터 수를 결정한 뒤, 클러스터별 소속 종목을 섹터 색상으로 시각화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b247f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b484a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적절한 클러스터 수 찾기 Elbow Method, Silhouette Score\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "inertias = []\n",
    "sil_scores = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = kmeans.fit_predict(X)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    sil_scores.append(silhouette_score(X, labels))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Elbow Method\n",
    "axes[0].plot(K_range, inertias, marker='o')\n",
    "axes[0].set_title('Elbow Method')\n",
    "axes[0].set_xlabel('Number of clusters (k)')\n",
    "axes[0].set_ylabel('Inertia')\n",
    "\n",
    "# Silhouette Score\n",
    "axes[1].plot(K_range, sil_scores, marker='o', color='orange')\n",
    "axes[1].set_title('Silhouette Score')\n",
    "axes[1].set_xlabel('Number of clusters (k)')\n",
    "axes[1].set_ylabel('Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적 n_clusters = 4\n",
    "log_norm_1 = np.log(normalized_1)\n",
    "X = StandardScaler().fit_transform(log_norm_1.T)\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "\n",
    "clusters = kmeans.fit_predict(X)\n",
    "cluster_df = pd.DataFrame({'Ticker': normalized_1.columns, 'Cluster': clusters})\n",
    "cluster_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b7f2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for c in range(kmeans.n_clusters):\n",
    "    ax = axes[c]\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    cluster_tickers = cluster_df[cluster_df['Cluster'] == c]['Ticker']\n",
    "    cluster_data = normalized_1[cluster_tickers]\n",
    "    \n",
    "    # 개별 종목을 섹터 색상으로 그리기\n",
    "    for ticker in cluster_tickers:\n",
    "        sector = sector_df.get(ticker, 'Unknown')\n",
    "        color = sector_colors.get(sector, 'grey')\n",
    "        ax.plot(cluster_data[ticker], color=color, alpha=0.3, linewidth=0.7)\n",
    "    \n",
    "    # 해당 클러스터의 중앙값 (군집 중앙점)\n",
    "    cluster_median = cluster_data.median(axis=1)\n",
    "    ax.plot(cluster_median, color='black', linewidth=2.5, linestyle='--', label=f'Cluster {c} Median')\n",
    "    \n",
    "    # 섹터 범례 (이 클러스터에 존재하는 섹터만)\n",
    "    cluster_sectors = sector_df[cluster_tickers].value_counts()\n",
    "    for sector, count in cluster_sectors.items():\n",
    "        ax.plot([], [], color=sector_colors.get(sector, 'grey'), linewidth=2, label=f'{sector} ({count})')\n",
    "    \n",
    "    ax.legend(fontsize=7, loc='upper left', ncol=2)\n",
    "    ax.set_title(f'Cluster {c} ({len(cluster_tickers)} stocks)')\n",
    "    ax.set_ylabel('Normalized Price (Log)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e16cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(kmeans.n_clusters):\n",
    "    cluster_tickers = cluster_df[cluster_df['Cluster'] == c]['Ticker']\n",
    "    cluster_data = normalized_1[cluster_tickers]\n",
    "    \n",
    "    # 최종 수익률\n",
    "    final_vals = cluster_data.iloc[-1]\n",
    "    \n",
    "    print(f\"=== Cluster {c} ({len(cluster_tickers)} stocks) ===\")\n",
    "    print(f\"  중앙값 최종: {cluster_data.median(axis=1).iloc[-1]:.1f} (={cluster_data.median(axis=1).iloc[-1]/100:.1f}x)\")\n",
    "    print(f\"  평균 최종:   {final_vals.mean():.1f} (={final_vals.mean()/100:.1f}x)\")\n",
    "    print(f\"  범위:        {final_vals.min():.1f} ~ {final_vals.max():.1f}\")\n",
    "    \n",
    "    # 섹터 구성\n",
    "    cluster_sectors = sector_df[cluster_tickers].value_counts()\n",
    "    print(f\"  섹터 구성:\")\n",
    "    for sector, count in cluster_sectors.items():\n",
    "        print(f\"    {sector}: {count}개\")\n",
    "    \n",
    "    # 대표 종목 (최종 정규화 값 기준 상위 3)\n",
    "    top3 = final_vals.nlargest(3)\n",
    "    print(f\"  상위 3종목: {', '.join([f'{t}({v:.0f})' for t, v in top3.items()])}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67b62d2",
   "metadata": {},
   "source": [
    "## 6. 상대강도 분석 — 시장을 이긴 진짜 승자 찾기\n",
    "\n",
    "종목 가격 / S&P 500 지수 가격으로 상대강도를 계산한다. 이 수치가 우상향하는 구간이 **시장보다 강한 진짜 랠리**이며, 단순히 시장과 함께 오른 종목과 초과수익을 낸 종목을 구분할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae8e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상대강도(RS) = 종목 정규화 가격 / NASDAQ 정규화 가격\n",
    "# 시작점=1로 정규화하여 비교\n",
    "# 1보다 위 = 나스닥 초과수익\n",
    "nasdaq = close_df_1['^IXIC'] if '^IXIC' in close_df_1.columns else None\n",
    "\n",
    "if nasdaq is not None:\n",
    "    nasdaq_norm = nasdaq / nasdaq.iloc[0]\n",
    "    rs_df = normalized_1.div(nasdaq_norm * 100, axis=0)  # normalized_1은 100 기준이므로 맞춤\n",
    "else:\n",
    "    print(\"NASDAQ 데이터가 없습니다\")\n",
    "    rs_df = None\n",
    "\n",
    "if rs_df is not None:\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    ax.set_yscale('log')\n",
    "    \n",
    "    # 섹터별로 개별 종목 RS 그리기\n",
    "    for sector, tickers in sector_df.groupby(sector_df):\n",
    "        color = sector_colors.get(sector, 'grey')\n",
    "        for ticker in tickers.index:\n",
    "            if ticker in rs_df.columns and ticker != '^IXIC':\n",
    "                ax.plot(rs_df[ticker], color=color, alpha=0.25, linewidth=0.6)\n",
    "        # 범례용 더미 라인\n",
    "        count = len([t for t in tickers.index if t in rs_df.columns and t != '^IXIC'])\n",
    "        if count > 0:\n",
    "            ax.plot([], [], color=color, linewidth=2, label=f'{sector} ({count})')\n",
    "    \n",
    "    # 전체 RS 중앙값\n",
    "    rs_median = rs_df.drop(columns=['^IXIC'], errors='ignore').median(axis=1)\n",
    "    ax.plot(rs_median, color='black', linewidth=2.5, linestyle='--', label='Median RS')\n",
    "    \n",
    "    # 기준선: RS=1은 나스닥과 동일 수익률\n",
    "    ax.axhline(1, color='red', linestyle='-', linewidth=2, label='RS=1 (NASDAQ)')\n",
    "    \n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Relative Strength vs NASDAQ (Log)')\n",
    "    ax.set_title('Relative Strength by Sector')\n",
    "    ax.legend(fontsize=7, loc='upper left', ncol=2)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pgtdhh6vakd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기간별 RS 차트 (4개 구간으로 분할)\n",
    "if rs_df is not None:\n",
    "    # 기간 정의\n",
    "    periods = [\n",
    "        ('1988.10 ~ 1991.12', '1988-10-01', '1991-12-31'),\n",
    "        ('1992.01 ~ 1994.12', '1992-01-01', '1994-12-31'),\n",
    "        ('1995.01 ~ 1997.12', '1995-01-01', '1997-12-31'),\n",
    "        ('1998.01 ~ 2000.03', '1998-01-01', '2000-03-31'),\n",
    "    ]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (period_name, start, end) in enumerate(periods):\n",
    "        ax = axes[idx]\n",
    "        ax.set_yscale('log')\n",
    "        \n",
    "        # 해당 기간 데이터 슬라이싱\n",
    "        rs_period = rs_df.loc[start:end]\n",
    "        \n",
    "        # 기간 시작점 기준으로 다시 정규화 (각 기간의 시작=1)\n",
    "        rs_period_norm = rs_period / rs_period.iloc[0]\n",
    "        \n",
    "        # 섹터별로 개별 종목 RS 그리기\n",
    "        for sector, tickers in sector_df.groupby(sector_df):\n",
    "            color = sector_colors.get(sector, 'grey')\n",
    "            for ticker in tickers.index:\n",
    "                if ticker in rs_period_norm.columns and ticker != '^IXIC':\n",
    "                    ax.plot(rs_period_norm[ticker], color=color, alpha=0.5, linewidth=0.6)\n",
    "        \n",
    "        # 해당 기간 RS 중앙값\n",
    "        rs_median = rs_period_norm.drop(columns=['^IXIC'], errors='ignore').median(axis=1)\n",
    "        ax.plot(rs_median, color='black', linewidth=2.5, linestyle='--', label='Median RS')\n",
    "        \n",
    "        # 기준선\n",
    "        ax.axhline(1, color='red', linestyle='-', linewidth=1.5, label='RS=1 (NASDAQ)')\n",
    "        \n",
    "        ax.set_title(f'{period_name}', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('RS (period start=1)')\n",
    "        ax.legend(fontsize=8, loc='upper left')\n",
    "    \n",
    "    plt.suptitle('Relative Strength by Period', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7453d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_rs_pattern(rs_series, median_series, threshold=0.1):\n",
    "    \"\"\"\n",
    "    RS 패턴을 4가지로 분류\n",
    "    1: 항상 위 (전 기간 중앙값/1 위)\n",
    "    2: 골든크로스 (약하다가 치고 오름)\n",
    "    3: 데드크로스 (강하다가 치고 내려감)\n",
    "    4: 항상 아래 (전 기간 중앙값/1 아래)\n",
    "    \"\"\"\n",
    "    rs = rs_series.dropna()\n",
    "    med = median_series.loc[rs.index]\n",
    "    \n",
    "    if len(rs) < 10:\n",
    "        return None\n",
    "    \n",
    "    # 기간을 전반/후반으로 나눔\n",
    "    mid = len(rs) // 2\n",
    "    first_half = rs.iloc[:mid]\n",
    "    second_half = rs.iloc[mid:]\n",
    "    med_first = med.iloc[:mid]\n",
    "    med_second = med.iloc[mid:]\n",
    "    \n",
    "    # 전반/후반 평균이 중앙값 대비 위인지 아래인지\n",
    "    first_above = (first_half > med_first).mean() > 0.6\n",
    "    first_below = (first_half < med_first).mean() > 0.6\n",
    "    second_above = (second_half > med_second).mean() > 0.6\n",
    "    second_below = (second_half < med_second).mean() > 0.6\n",
    "    \n",
    "    if first_above and second_above:\n",
    "        return 1  # 항상 위\n",
    "    elif first_below and second_above:\n",
    "        return 2  # 골든크로스\n",
    "    elif first_above and second_below:\n",
    "        return 3  # 데드크로스\n",
    "    elif first_below and second_below:\n",
    "        return 4  # 항상 아래\n",
    "    else:\n",
    "        return 0  # 분류 불가 (혼재)\n",
    "\n",
    "# 기간별로 분류 실행\n",
    "periods = [\n",
    "    ('1988.10~1991.12', '1988-10-01', '1991-12-31'),\n",
    "    ('1992.01~1994.12', '1992-01-01', '1994-12-31'),\n",
    "    ('1995.01~1997.12', '1995-01-01', '1997-12-31'),\n",
    "    ('1998.01~2000.03', '1998-01-01', '2000-03-31'),\n",
    "]\n",
    "\n",
    "pattern_results = {}\n",
    "\n",
    "for period_name, start, end in periods:\n",
    "    rs_period = rs_df.loc[start:end]\n",
    "    rs_period_norm = rs_period / rs_period.iloc[0]\n",
    "    rs_median = rs_period_norm.drop(columns=['^IXIC'], errors='ignore').median(axis=1)\n",
    "    \n",
    "    period_patterns = {}\n",
    "    for ticker in rs_period_norm.columns:\n",
    "        if ticker == '^IXIC':\n",
    "            continue\n",
    "        pattern = classify_rs_pattern(rs_period_norm[ticker], rs_median)\n",
    "        if pattern is not None:\n",
    "            period_patterns[ticker] = pattern\n",
    "    \n",
    "    pattern_results[period_name] = period_patterns\n",
    "    \n",
    "    # 결과 요약\n",
    "    from collections import Counter\n",
    "    counts = Counter(period_patterns.values())\n",
    "    print(f\"\\n=== {period_name} ===\")\n",
    "    print(f\"1. 항상 위: {counts.get(1, 0)}개\")\n",
    "    print(f\"2. 골든크로스: {counts.get(2, 0)}개\")\n",
    "    print(f\"3. 데드크로스: {counts.get(3, 0)}개\")\n",
    "    print(f\"4. 항상 아래: {counts.get(4, 0)}개\")\n",
    "    print(f\"0. 분류불가: {counts.get(0, 0)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4ebc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전 기간 걸쳐 일관된 패턴을 보이는 종목 찾기\n",
    "from collections import defaultdict\n",
    "\n",
    "# 종목별 기간별 패턴 취합\n",
    "ticker_patterns = defaultdict(list)\n",
    "for period_name, patterns in pattern_results.items():\n",
    "    for ticker, pattern in patterns.items():\n",
    "        ticker_patterns[ticker].append((period_name, pattern))\n",
    "\n",
    "# 항상 위 (4개 기간 모두 1번)\n",
    "always_above = [t for t, patterns in ticker_patterns.items() \n",
    "                if len(patterns) == 4 and all(p[1] == 1 for p in patterns)]\n",
    "\n",
    "# 항상 아래 (4개 기간 모두 4번)\n",
    "always_below = [t for t, patterns in ticker_patterns.items() \n",
    "                if len(patterns) == 4 and all(p[1] == 4 for p in patterns)]\n",
    "\n",
    "# 상승 추세 (초기에 아래→후기에 위)\n",
    "rising = [t for t, patterns in ticker_patterns.items()\n",
    "          if len(patterns) == 4 and patterns[0][1] in [4, 0] and patterns[3][1] == 1]\n",
    "\n",
    "# 하락 추세 (초기에 위→후기에 아래)\n",
    "falling = [t for t, patterns in ticker_patterns.items()\n",
    "           if len(patterns) == 4 and patterns[0][1] == 1 and patterns[3][1] in [4, 0]]\n",
    "\n",
    "print(\"=== 전 기간 일관된 패턴 ===\\n\")\n",
    "\n",
    "print(f\"1. 12년간 항상 나스닥을 이긴 종목 ({len(always_above)}개):\")\n",
    "for t in always_above:\n",
    "    sector = sector_df.get(t, 'Unknown')\n",
    "    print(f\"  {t} ({sector})\")\n",
    "\n",
    "print(f\"\\n2. 12년간 항상 나스닥에 진 종목 ({len(always_below)}개):\")\n",
    "for t in always_below:\n",
    "    sector = sector_df.get(t, 'Unknown')\n",
    "    print(f\"  {t} ({sector})\")\n",
    "\n",
    "print(f\"\\n3. 초기 약세 → 후기 강세로 전환 ({len(rising)}개):\")\n",
    "for t in rising:\n",
    "    sector = sector_df.get(t, 'Unknown')\n",
    "    print(f\"  {t} ({sector})\")\n",
    "\n",
    "print(f\"\\n4. 초기 강세 → 후기 약세로 전환 ({len(falling)}개):\")\n",
    "for t in falling:\n",
    "    sector = sector_df.get(t, 'Unknown')\n",
    "    print(f\"  {t} ({sector})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2179a9c",
   "metadata": {},
   "source": [
    "### RS 분석 결과\n",
    "\n",
    "**12년간 일관되게 나스닥을 이긴 종목**: AB, AEG (Financial Services), LEG (Consumer Cyclical) — 단 3개\n",
    "\n",
    "**초기 약세 → 후기 강세 전환 (25개)**: AAPL, AMAT, BBY, COST, SPGI 등\n",
    "\n",
    "**초기 강세 → 후기 약세 전환 (24개)**: BA, NSC, BEN, SLB 등 전통 산업재/에너지\n",
    "\n",
    "---\n",
    "\n",
    "### 관찰된 패턴\n",
    "\n",
    "1. **12년간 일관된 초과수익 종목은 극소수** — 162개 중 3개(1.9%)만이 전 기간 나스닥을 상회. 대부분의 종목은 특정 시기에만 강세를 보임\n",
    "\n",
    "2. **후반부 강세 전환 종목의 특징** — AAPL, AMAT, BBY 등은 초기 7~8년간 지수 대비 약세였다가 후반부에 급등. 이 패턴이 \"캐즘 후 성장\"인지 \"우연\"인지는 추가 검증 필요\n",
    "\n",
    "3. **전통 산업재의 상대적 약세** — BA, NSC, SLB 등 설비 집약적 종목들은 초기 강세 후 후반부에 지수 대비 약세로 전환\n",
    "\n",
    "4. **Financial Services의 안정적 성과** — 일관된 초과수익 3개 종목 중 2개가 금융 섹터. 다만 이것이 \"기술 혁신의 간접 수혜\" 때문인지는 데이터만으로 단정할 수 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qcqf2394n4c",
   "metadata": {},
   "source": [
    "## 7. 그룹 2 분석 — 버블 말기 1년 (1999.03 ~ 2000.03)\n",
    "\n",
    "339개 종목 전체를 대상으로 버블 말기 1년간의 패턴을 분석한다. 12년 전체를 경험한 그룹 1과 비교하여 **버블 말기에 새로 진입한 종목들의 특성**을 파악한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q71aho3alc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹 2 정규화 (1999.03 시작점 = 100)\n",
    "normalized_2 = close_df_2.apply(lambda x: x / x.iloc[0] * 100)\n",
    "\n",
    "# 그룹 2 섹터 정보 수집 (그룹 1에 없는 종목만 추가)\n",
    "sectors_2 = {}\n",
    "new_tickers = [t for t in close_df_2.columns if t not in sector_df.index]\n",
    "print(f\"그룹 2 신규 종목: {len(new_tickers)}개\")\n",
    "\n",
    "for ticker in new_tickers:\n",
    "    try:\n",
    "        info = yf.Ticker(ticker).info\n",
    "        sectors_2[ticker] = info.get('sector', 'Unknown')\n",
    "    except:\n",
    "        sectors_2[ticker] = 'Unknown'\n",
    "\n",
    "# 기존 섹터 정보와 병합\n",
    "sector_df_2 = pd.concat([sector_df, pd.Series(sectors_2)])\n",
    "sector_df_2 = sector_df_2[~sector_df_2.index.duplicated(keep='first')]\n",
    "\n",
    "print(f\"그룹 2 섹터 분포:\")\n",
    "print(sector_df_2[close_df_2.columns].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8u2y5zzryb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹 2 섹터별 로그 차트\n",
    "plot_sector_chart(normalized_2, sector_df_2[close_df_2.columns], sector_colors, \n",
    "                  '1999.03 ~ 2000.03 Rally by Sector (339 stocks)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "to6j6hkj6eh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹 2 클러스터링 (k=4)\n",
    "kmeans_2, cluster_df_2, X_2 = run_clustering(normalized_2, n_clusters=4)\n",
    "plot_cluster_chart(normalized_2, cluster_df_2, sector_df_2, sector_colors, n_clusters=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fs9l9uzdj4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그룹 2 클러스터별 통계 요약\n",
    "summarize_clusters(normalized_2, cluster_df_2, sector_df_2, n_clusters=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0x6hznxqvv",
   "metadata": {},
   "source": [
    "### 그룹 2 분석 결과\n",
    "\n",
    "| 클러스터 | 종목 수 | 1년 수익률 (중앙값) | 주요 섹터 |\n",
    "|----------|---------|---------------------|-----------|\n",
    "| 폭등 | ~30개 | ~4배 | Technology 다수 |\n",
    "| 상승 | ~100개 | ~1.5배 | 전 섹터 분포 |\n",
    "| 횡보 | ~100개 | ~1배 | 전 섹터 분포 |\n",
    "| 하락 | ~100개 | ~-50% | Financial Services, Industrials |\n",
    "\n",
    "**그룹 2 특징**:\n",
    "- 1년이라는 짧은 기간에도 **극단적 양극화** — 4배 상승과 -50% 하락이 공존\n",
    "- **Technology 섹터가 폭등 클러스터에 집중** — 12년 분석과 달리 버블 말기에는 테크 직접 수혜\n",
    "- **손실 비율이 높음** — 339개 중 약 37%가 마이너스 수익률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92w6g38gock",
   "metadata": {},
   "source": [
    "## 8. 결론\n",
    "\n",
    "### 그룹 1 vs 그룹 2 비교\n",
    "\n",
    "| 지표 | 그룹 1 (12년) | 그룹 2 (1년) |\n",
    "|------|---------------|--------------|\n",
    "| 중앙값 수익률 | 3.88배 | 1.08배 |\n",
    "| 95% 신뢰구간 | **[3.08배, 4.35배]** | **[1.02배, 1.12배]** |\n",
    "| 손실 종목 비율 | 2% (4개) | 37% (~125개) |\n",
    "| 슈퍼 성장 주도 섹터 | Financial Services | Technology |\n",
    "\n",
    "### 통계적 검증 결과\n",
    "\n",
    "| 검증 | 그룹 1 | 그룹 2 | 해석 |\n",
    "|------|--------|--------|------|\n",
    "| Kruskal-Wallis | 유의미 | 유의미 | 클러스터 구분이 통계적으로 의미있음 |\n",
    "| 카이제곱 | **독립** | **연관** | 그룹1은 섹터 무관, 그룹2는 Tech 집중 |\n",
    "| Bootstrap 95% CI | [3.08x, 4.35x] | [1.02x, 1.12x] | 두 그룹 CI 겹치지 않음 → 차이 유의미 |\n",
    "\n",
    "### 핵심 발견\n",
    "\n",
    "**그룹 1 (12년 장기)**:\n",
    "- 섹터와 성과가 독립적 → **섹터보다 종목 선별이 중요**\n",
    "- Bootstrap 하한 3.08배 → 최악의 경우에도 3배 이상 (Survivorship Bias 감안 필요)\n",
    "- 슈퍼 성장 클러스터에서 Financial Services(14개) > Technology(7개)\n",
    "\n",
    "**그룹 2 (버블 말기 1년)**:\n",
    "- 섹터와 성과가 연관됨 → **Tech/바이오가 성장 클러스터에 집중**\n",
    "- 중앙값 1.08배, CI도 [1.02x, 1.12x]로 좁음 → 대부분 본전치기\n",
    "- 37% 손실 vs 일부 4배 → **\"운 좋으면 4배, 아니면 -50%\" 도박장 구조**\n",
    "\n",
    "### 한계\n",
    "\n",
    "- **Survivorship Bias**: 상장폐지 종목 누락. 손실 비율(2%, 37%)은 과소추정\n",
    "- \"12년 보유 시 최소 3배\"는 **생존한 종목에 한정된 결과**\n",
    "- 추후 FMP API로 상장폐지 종목 포함 재분석 필요\n",
    "\n",
    "### 후속 과제\n",
    "\n",
    "- [ ] FMP API로 Survivorship Bias 해소\n",
    "- [ ] 2009~2021 빅테크 랠리 분석\n",
    "- [ ] 현재 AI 랠리의 RS 분석으로 초기/중기/말기 판단"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
